{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ICASSP 2024 SP Grand Challenge on Hyperspectral Skin Vision: Can Your Camera See beyond Your Skin? Introducing ICASSP 2024 SPGC competition aiming at reconstructing skin spectral reflectance in the visible (VIS) and near-infrared (NIR) spectral range from RGB images captured by everyday cameras, offering a transformative approach for cosmetic and beauty applications. By reconstructing the skin spectral reflectance in both VIS and NIR spectrum, this competition aims to provide rich hyperspectral information accessible on consumer devices. With the reconstructed skin spectral, we pave the way for the creation of personalized beauty and skincare solutions directly through consumers' smartphones and other accessible devices. With the goal of democratizing skin analysis and advancing the field of beauty technology, this competition invites computer vision researchers, machine learning experts, and cosmetic professionals to participate in skin spectral reconstruction, making personalized beauty and skincare are accessible to all. Register today to participate! Important Dates Sep 20, 2023: Registration opens Sep 25, 2023: Release of the training and validation sets, the baseline methods and the evaluation metrics Oct 25, 2023: Release of the evaluation set and starts the leaderboard Nov 25, 2023: Submission close Dec 25, 2023: Winners annoucement Jan 2, 2024: Grand Challenge 2-page papers due (by invitation only) Jan 16, 2024: Grand Challenge 2-page paper acceptance notification Jan 23, 2024: Camera-ready Grand Challenge 2-page papers due June 19, 2024: Grand Challenge OJ-SP papers due (by invitation only) Task Overview The skin spectral reconstruction task aims to reconstruct the skin spectral image cube from the given RGB image. Let \\(R \\in \\mathbb{R}^{w \\times h \\times c}\\) be the RGB image and \\(S \\in \\mathbb{R}^{w \\times h \\times C}\\) the skin spectral, where \\(c<<C\\) , the task is to finding a function \\(f\\) that reconstruct \\(S\\) from \\(R\\) , as described below: \\[ S = f(R; \\Theta). \\] The function \\(f(\\cdot; \\Theta)\\) parameterized by \\(\\Theta\\) can be implemented using a deep learning model or any other analytical model that can effectively learn the mapping between RGB and hyperspectral images. The task is both scientifically and technically challenging, but not impossible to solve. In this competition, participants will have access to two distinct datasets. The first dataset comprises a pair of RGB and VIS data, while the second dataset consists of a pair of MSI (RGB + infrared image at 960 nm) and NIR data. The challenge is to develop a single model capable of reconstructing skin spectral information across both the VIS spectrum (400 - 700 nm) and the NIR spectrum (700 - 1000 nm) using the MSI data, which is generated with a real camera response function. Detailed instructions on how to request access to the datasets are available here . Evaluation Criteria The reconstructed skin spectral will be evaluated from both spatial and spectral domains, with the Structural Similarity Index (SSIM) and the Spectral Angle Mapper (SAM). During the evaluation process, a mask will be employed to exclude the background image, ensuring that the assessment remains centered on the human skin spectral characteristics. The evaluation metrics will be provided to the registered participant who has signed the EULA through our Github. More information is available [here]{/participate} Baseline For the task to skin spectral reconstruction, we will use the Mask-guided Spectral-wise Transformer (MST) published in 2022 CVPR conference as the baseline solution. This method leverages a transformer-based architecture that takes RGB images as input and generates corresponding skin spectral data. The data loading and baseline methods are provided here .","title":"Hyper-Skin SPGC"},{"location":"#task-overview","text":"The skin spectral reconstruction task aims to reconstruct the skin spectral image cube from the given RGB image. Let \\(R \\in \\mathbb{R}^{w \\times h \\times c}\\) be the RGB image and \\(S \\in \\mathbb{R}^{w \\times h \\times C}\\) the skin spectral, where \\(c<<C\\) , the task is to finding a function \\(f\\) that reconstruct \\(S\\) from \\(R\\) , as described below: \\[ S = f(R; \\Theta). \\] The function \\(f(\\cdot; \\Theta)\\) parameterized by \\(\\Theta\\) can be implemented using a deep learning model or any other analytical model that can effectively learn the mapping between RGB and hyperspectral images. The task is both scientifically and technically challenging, but not impossible to solve. In this competition, participants will have access to two distinct datasets. The first dataset comprises a pair of RGB and VIS data, while the second dataset consists of a pair of MSI (RGB + infrared image at 960 nm) and NIR data. The challenge is to develop a single model capable of reconstructing skin spectral information across both the VIS spectrum (400 - 700 nm) and the NIR spectrum (700 - 1000 nm) using the MSI data, which is generated with a real camera response function. Detailed instructions on how to request access to the datasets are available here .","title":"Task Overview"},{"location":"#evaluation-criteria","text":"The reconstructed skin spectral will be evaluated from both spatial and spectral domains, with the Structural Similarity Index (SSIM) and the Spectral Angle Mapper (SAM). During the evaluation process, a mask will be employed to exclude the background image, ensuring that the assessment remains centered on the human skin spectral characteristics. The evaluation metrics will be provided to the registered participant who has signed the EULA through our Github. More information is available [here]{/participate}","title":"Evaluation Criteria"},{"location":"#baseline","text":"For the task to skin spectral reconstruction, we will use the Mask-guided Spectral-wise Transformer (MST) published in 2022 CVPR conference as the baseline solution. This method leverages a transformer-based architecture that takes RGB images as input and generates corresponding skin spectral data. The data loading and baseline methods are provided here .","title":"Baseline"},{"location":"committee/","text":"Warning The site is currently incomplete, and the missing sections will be published on September 20th. Please stay tuned for updates.","title":"Committee"},{"location":"contact/","text":"Warning The site is currently incomplete, and the missing sections will be published on September 20th. Please stay tuned for updates.","title":"Contact"},{"location":"dataset/","text":"title: Dataset summary: ICASSP 2024 SPGC on Hyper-Skin Vision authors: - Pc Ng - Olivia Liu date: 2023-06-09 Click Me! The data that will be used in the competition is carefully collected and curated following the ethical guidelines approved by the Human Research Ethics Program (HREP) at the University of Toronto. Figure below shows the schematic of our setup for the data collection. The image on the right side illustrates our experimental set up for the data collection, while the right side provides a schematic representation of the set up. The hyperspectral camera used to collect the hyperspectral image is Specim FX10. The Specim FX10 camera has a spectral range of 400-1000 nm, with a total of 448 bands, and a spatial resolution of 1024 \\(\\times\\) 1024 pixels. The frame rate of the camera is set to 45 Hz. Since the Specim FX10 is a line-scan camera, it took approximately 22.7 s to finish scan the entire hypercube of dimension 1024 \\(\\times\\) 1024 \\(\\times\\) 448. The camera was placed at a distance of 40 cm from the subject, who was required to sit on a stool during the data collection. To ensure sufficient lighting for the imaging process, two halogen lights were used and pointed at 45 degrees to the subject. The halogen lights were used because they have a broad spectrum and provide stable illumination for the imaging process. A total of six images were captured for each subject: three neutral images (left, front, right) and three smiling images (left, front, right). A total of 51 subjects (27 male and 24 female, age from 17 to 60, 46 Asian, 4 European, and 1 Latino) participated in the experiments, with six images per participant. In total, there are 306 hyperspectral images and their corresponding RGB images will be used for the competition. During data collection, participants' personal information will not be recorded in the database, and only a file linking unique ID numbers to participants. All the data is collected with permission from participants who sign an informed consent form, and the data is ready for use in the competition. Please refer to this link for the dataset description and the instructions to access the data.","title":"Dataset"},{"location":"participate/","text":"Warning The site is currently incomplete, and the missing sections will be published on September 20th. Please stay tuned for updates. How to participate? To join the competition, follow these steps: Rules and Engagement: Eligibility : The competition is open to anyone interested in skin spectral analysis, regardless of their affiliations or backgrounds. Participants must register through the designated registration process and agree to abide by the competition rules. Registration : To register for the competition, participants must provide valid email addresses for all team members. Double registration is not allowed, meaning a team member cannot be in different groups. Data Usage : Participants can use external data and pretrained models in their submissions. However, they must submit a request for the external data sources and pretrained models they will use before the release of the validation data. This external data source and pretrained model will be made available in our online forum so that other participants can access them to ensure fairness. Submission Limit : To avoid cheating and ensure fairness, each team is limited to a maximum of three submissions per day. Validation : The submitted results will be evaluated on the validation data set, and the organizers will keep a hidden test set for final evaluation. Presentation : The top-performing team will be invited to give a talk during a workshop at an in-person event to showcase their solution. Additionally, they will be invited to co-author the paper to be submitted to the NeurIPS Datasets and Benchmarks Track in 2024. Clear requirements for authorship levels in the publication process will be provided. Ethical Considerations : Participants are expected to follow ethical guidelines while conducting their research and submitting their results. Fairness : The competition will be conducted in a fair and transparent manner. Any disputes or concerns will be addressed promptly by the organizers. Code of Conduct : Participants must adhere to the competition's code of conduct, which prohibits harassment, discrimination, and other inappropriate behavior. Disqualification : The organizers reserve the right to disqualify any participant who violates the competition rules or engages in unethical or inappropriate behavior. NOTE: the intellectual property (IP) is not transferred to the challenge organizers, i.e., if code is shared/submitted, the participants remain the owners of their code (when the code is made publicly available, an appropriate license should be added).","title":"Participate"},{"location":"participate/#how-to-participate","text":"To join the competition, follow these steps:","title":"How to participate?"},{"location":"participate/#rules-and-engagement","text":"Eligibility : The competition is open to anyone interested in skin spectral analysis, regardless of their affiliations or backgrounds. Participants must register through the designated registration process and agree to abide by the competition rules. Registration : To register for the competition, participants must provide valid email addresses for all team members. Double registration is not allowed, meaning a team member cannot be in different groups. Data Usage : Participants can use external data and pretrained models in their submissions. However, they must submit a request for the external data sources and pretrained models they will use before the release of the validation data. This external data source and pretrained model will be made available in our online forum so that other participants can access them to ensure fairness. Submission Limit : To avoid cheating and ensure fairness, each team is limited to a maximum of three submissions per day. Validation : The submitted results will be evaluated on the validation data set, and the organizers will keep a hidden test set for final evaluation. Presentation : The top-performing team will be invited to give a talk during a workshop at an in-person event to showcase their solution. Additionally, they will be invited to co-author the paper to be submitted to the NeurIPS Datasets and Benchmarks Track in 2024. Clear requirements for authorship levels in the publication process will be provided. Ethical Considerations : Participants are expected to follow ethical guidelines while conducting their research and submitting their results. Fairness : The competition will be conducted in a fair and transparent manner. Any disputes or concerns will be addressed promptly by the organizers. Code of Conduct : Participants must adhere to the competition's code of conduct, which prohibits harassment, discrimination, and other inappropriate behavior. Disqualification : The organizers reserve the right to disqualify any participant who violates the competition rules or engages in unethical or inappropriate behavior. NOTE: the intellectual property (IP) is not transferred to the challenge organizers, i.e., if code is shared/submitted, the participants remain the owners of their code (when the code is made publicly available, an appropriate license should be added).","title":"Rules and Engagement:"}]}